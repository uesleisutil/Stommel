{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File name**: evaluation_roms_class.ipynb\n",
    "\n",
    "**Author**:  Ueslei Adriano Sutil\n",
    "\n",
    "**Email**: [ueslei@putlook.com](mailto:ueslei@putlook.com)\n",
    "\n",
    "**Created**: 01 September 2020\n",
    "\n",
    "**Last modified**: 04 September 2020\n",
    "\n",
    "**Version**: 1.5\n",
    "\n",
    "**Python**: 3.7.9\n",
    "- - -\n",
    "<br>\n",
    "\n",
    "\n",
    "**1. Evaluate ROMS output using:**\n",
    "\n",
    "- Bias (Contour);\n",
    "<br>\n",
    "$\n",
    "\\begin{equation}\n",
    "BIAS = A_{t}-F_{t}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "- Root Mean Square Error (RMSE; Contour);\n",
    "<br>\n",
    "$\n",
    "\\begin{equation}\n",
    "RMSE = \\sqrt{\\sum_{i=1}^{n}\\frac{(A_{t}-F_{t})^2}{n}}\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "- Mean Absolute Percentage Error (MAPE; Contour);\n",
    "<br>\n",
    "$\n",
    "\\begin{equation}\n",
    "MAPE = \\frac{1}{n}\\sum_{t=1}^{n}\\left | \\frac{A_{t}-F_{t}}{A_{t}} \\right |\n",
    "\\end{equation}\n",
    "$\n",
    "<br>\n",
    "\n",
    "Where $A_{t}$ is the actual value, $F_{t}$ is the forecast value and $n$ is the number of observations.\n",
    "<br>\n",
    "\n",
    "**2. Compare ROMS output with:**\n",
    "- GLORYS12V1 (Fernandez & Lellouch, 2018; [[Access here]](http://marine.copernicus.eu/services-portfolio/access-to-products/?option=com_csw&view=details&product_id=GLOBAL_REANALYSIS_PHY_001_030)):)\n",
    "    - Sea Surface Temperature (°C);\n",
    "    - Current Speed at surface (m.s⁻¹).\n",
    "\n",
    "- OSCAR (Bonjean & Lagerloef et al., 2002; [[Access here]](https://podaac.jpl.nasa.gov/dataset/OSCAR_L4_OC_third-deg)):\n",
    "    - Ocean Current Speed at surface (m.s⁻¹);\n",
    "\n",
    "\n",
    "**3. Disclaimers:**\n",
    "- Both Observed and Simulated variables needs to match the same time-step. \n",
    "- ROMS has a better spatial resolution than both database.\n",
    "- Post-process ROMS outputs to match with the databases:<br>\n",
    "  \n",
    "    - MUR and GLORYS (Daily data):<br>\n",
    "            `ncks -v temp,u,v -d s_rho,29,29 roms_his.nc roms_evaluation.nc`\n",
    "            `cdo daymean roms_evaluation.nc roms_evaluation_mean.nc`\n",
    "            `cdo splitday roms_evaluation_mean.nc roms_evaluation_mean`\n",
    "            `cdo cat roms_evaluation_mean01 roms_evaluation_mean02 ... roms_ts_daymean.nc`\n",
    "   \n",
    "    - OSCAR (Each 5 days data):<br>\n",
    "            `ncks -v u,v -d s_rho,49,49 roms_avg.nc roms_evaluation.nc`\n",
    "            `cdo daymean roms_evaluation.nc roms_evaluation_mean.nc`\n",
    "            `cdo splitday roms_evaluation_mean.nc roms_evaluation_mean`\n",
    "            `cdo cat roms_evaluation_mean21 roms_evaluation_mean26 roms_evaluation_final.nc`\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import libraries and create needed definitions and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import pyresample\n",
    "import cmocean\n",
    "import os\n",
    "from   mpl_toolkits.basemap import Basemap\n",
    "from   wrf                  import getvar,extract_times\n",
    "from   tqdm                 import tqdm\n",
    "from   time                 import sleep\n",
    "from   IPython.display      import display\n",
    "import numpy                as np\n",
    "import matplotlib.pyplot    as plt\n",
    "import ipywidgets           as widgets\n",
    "import pandas               as pd\n",
    "\n",
    "def bbox2ij(lon,lat,bbox=[-160., -155., 18., 23.]):\n",
    "    \"\"\"Return indices for i,j that will completely cover the specified bounding box.\n",
    "   \n",
    "    i0,i1,j0,j1 = bbox2ij(lon,lat,bbox)\n",
    "    \n",
    "    lon,lat = 2D arrays that are the target of the subset\n",
    "    bbox = list containing the bounding box: [lon_min, lon_max, lat_min, lat_max]\n",
    "\n",
    "    Example\n",
    "    -------  \n",
    "    >>> i0,i1,j0,j1 = bbox2ij(lon_rho,[-71, -63., 39., 46])\n",
    "    >>> h_subset = nc.variables['h'][j0:j1,i0:i1]       \n",
    "    \"\"\"\n",
    "    bbox=np.array(bbox)\n",
    "    mypath=np.array([bbox[[0,1,1,0]],bbox[[2,2,3,3]]]).T\n",
    "    p = path.Path(mypath)\n",
    "    points = np.vstack((lon.flatten(),lat.flatten())).T\n",
    "    n,m = np.shape(lon)\n",
    "    inside = p.contains_points(points).reshape((n,m))\n",
    "    ii,jj = np.meshgrid(range(m),range(n))\n",
    "    return min(ii[inside]),max(ii[inside]),min(jj[inside]),max(jj[inside])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Choose which datase, variable and metric will be used to compare with ROMS output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb9ee011c4b41be947746e1d57bd312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(button_style='info', description='Dataset:', options=(('GLORYS', 1), ('OSCAR', 2)), style=Toggle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = widgets.ToggleButtons(\n",
    "    options=[(\"GLORYS\", 1), (\"OSCAR\", 2)],\n",
    "    description='Dataset:',\n",
    "    button_style='info')\n",
    "\n",
    "dataset.style.button_width = '170px'\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74122120fc44542b674f7984e2ad9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(button_style='info', description='Variable:', options=(('Sea Surface Temperature', 1), ('Sea Sur…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if dataset.value == 1:\n",
    "    variable = widgets.ToggleButtons(\n",
    "        options=[(\"Sea Surface Temperature\", 1), (\"Sea Surface Currents\", 2)],\n",
    "        description='Variable:',\n",
    "        button_style='info',\n",
    "    )\n",
    "    variable.style.button_width = '170px'\n",
    "    display(variable)\n",
    "elif dataset.value == 2:\n",
    "    print('OSCAR has only one variable. Choosing Surface Current.')\n",
    "    class variable: pass\n",
    "    variable.somefield1 = 'value'\n",
    "    setattr(variable, 'value','value')\n",
    "    variable.value = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 3. Set customizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set map boundaries.\n",
    "bbox      = [-53,-43,-33,-23]\n",
    "lonbounds = [-53,-43] \n",
    "latbounds = [-33,-23]\n",
    "\n",
    "# Open files url and read CSV data with Pandas.\n",
    "if dataset.value == 1 and variable.value == 1:\n",
    "    expected_temp_url = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/expected_roms_temp.csv'\n",
    "    expected_lat_url  = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/expected_roms_lat.csv'\n",
    "    expected_lon_url  = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/expected_roms_lon.csv'\n",
    "    \n",
    "    observed_temp_url = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/observed_glorys_temp.csv'\n",
    "    observed_lat_url  = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/observed_glorys_lat.csv'\n",
    "    observed_lon_url  = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/observed_glorys_lon.csv'\n",
    "\n",
    "    expected_temp_csv = pd.read_csv(expected_temp_url, sep = \",\")\n",
    "    expected_lat_csv  = pd.read_csv(expected_lat_url, sep = \",\")\n",
    "    expected_lon_csv  = pd.read_csv(expected_lon_url, sep = \",\")\n",
    "\n",
    "    observed_temp_csv = pd.read_csv(observed_temp_url, sep = \",\")\n",
    "    observed_lat_csv  = pd.read_csv(observed_lat_url, sep = \",\")\n",
    "    observed_lon_csv  = pd.read_csv(observed_lon_url, sep = \",\")\n",
    "\n",
    "elif dataset.value == 1 and variable.value == 2 :\n",
    "    expected_u_url    = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/expected_roms_u.csv'\n",
    "    expected_v_url    = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/expected_roms_v.csv'\n",
    "    expected_lat_url  = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/expected_roms_lat.csv'\n",
    "    expected_lon_url  = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/expected_roms_lon.csv'\n",
    "       \n",
    "    observed_u_url    = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/observed_glorys_u.csv'\n",
    "    observed_v_url    = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/observed_glorys_v.csv'\n",
    "    observed_lat_url  = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/observed_glorys_lat.csv'\n",
    "    observed_lon_url  = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/observed_glorys_lon.csv'\n",
    "\n",
    "    expected_u_csv    = pd.read_csv(expected_u_url, sep = \",\")\n",
    "    expected_v_csv    = pd.read_csv(expected_v_url, sep = \",\")   \n",
    "    expected_lat_csv  = pd.read_csv(expected_lat_url, sep = \",\")\n",
    "    expected_lon_csv  = pd.read_csv(expected_lon_url, sep = \",\")\n",
    "\n",
    "    observed_u_csv    = pd.read_csv(observed_u_url, sep = \",\")\n",
    "    observed_v_csv    = pd.read_csv(observed_v_url, sep = \",\")  \n",
    "    observed_lat_csv  = pd.read_csv(observed_lat_url, sep = \",\")\n",
    "    observed_lon_csv  = pd.read_csv(observed_lon_url, sep = \",\")\n",
    "elif dataset.value == 2 and variable.value == 2 :\n",
    "    expected_u_url    = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/expected_roms_u.csv'\n",
    "    expected_v_url    = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/expected_roms_v.csv'\n",
    "    observed_u_url    = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/observed_oscar_u.csv'\n",
    "    observed_v_url    = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/observed_oscar_v.csv'   \n",
    "    observed_lat_url  = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/observed_oscar_lat.csv'\n",
    "    observed_lon_url  = 'https://raw.githubusercontent.com/uesleisutil/Stommel/master/Examples/ROMS_Evaluation/inputs/observed_oscar_lon.csv'\n",
    "\n",
    "    expected_u_csv    = pd.read_csv(expected_u_url, sep = \",\")\n",
    "    expected_v_csv    = pd.read_csv(expected_v_url, sep = \",\")   \n",
    "    expected_lat_csv  = pd.read_csv(expected_lat_url, sep = \",\")\n",
    "    expected_lon_csv  = pd.read_csv(expected_lon_url, sep = \",\")\n",
    "\n",
    "    observed_u_csv    = pd.read_csv(observed_u_url, sep = \",\")\n",
    "    observed_v_csv    = pd.read_csv(observed_v_url, sep = \",\")  \n",
    "    observed_lat_csv  = pd.read_csv(observed_lat_url, sep = \",\")\n",
    "    observed_lon_csv  = pd.read_csv(observed_lon_url, sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Collect data from the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate observed data lat/lon coords based on the bounds chosen at step 3.\n",
    "latli = np.argmin(np.abs(observed_lat_csv-latbounds[1]))\n",
    "latui = np.argmin(np.abs(observed_lat_csv-latbounds[0])) \n",
    "lonli = np.argmin(np.abs(observed_lon_csv-lonbounds[0]))\n",
    "lonui = np.argmin(np.abs(observed_lon_csv-lonbounds[1])) \n",
    "\n",
    "raise SystemError(0)\n",
    "# Reopen lat/lon coords with the exactly gridpoin based on the chosen bounds.\n",
    "if dataset == '1':\n",
    "    lon_obs = nc_obs.variables['longitude'][lonli:lonui]\n",
    "    lat_obs = nc_obs.variables['latitude'][latui:latli]\n",
    "elif dataset == '2':\n",
    "    lon_obs = nc_obs.variables['longitude'][lonli:lonui]-360\n",
    "    lat_obs = nc_obs.variables['latitude'][latli:latui]\n",
    "\n",
    "# Lon/lat.\n",
    "lon_obs,lat_obs = np.meshgrid(lon_obs,lat_obs)\n",
    "lat_obs_len = len(lat_obs[:,0])\n",
    "lon_obs_len = len(lon_obs[0, :])\n",
    "lat_obs_len = len(lat_obs[:])\n",
    "lon_obs_len = len(lon_obs[:])\n",
    "\n",
    "# Count how many time steps in file.\n",
    "loop = len(nc_obs.variables['time'][:])   \n",
    "\n",
    "# Create variable to store data.\n",
    "if dataset == '1' and contourf_var == '1':\n",
    "    var = np.zeros([loop,lat_obs_len,lon_obs_len])\n",
    "    observed = np.zeros([loop,lat_obs_len,lon_obs_len])\n",
    "elif dataset == '1' and contourf_var == '2':\n",
    "    var1 = np.zeros([loop,lat_obs_len,lon_obs_len])\n",
    "    var2 = np.zeros([loop,lat_obs_len,lon_obs_len])\n",
    "    observed1 = np.zeros([loop,lat_obs_len,lon_obs_len])\n",
    "    observed2 = np.zeros([loop,lat_obs_len,lon_obs_len])   \n",
    "elif dataset == '2':\n",
    "    var1 = np.zeros([loop,lat_obs_len,lon_obs_len])\n",
    "    var2 = np.zeros([loop,lat_obs_len,lon_obs_len])\n",
    "    observed1 = np.zeros([loop,lat_obs_len,lon_obs_len])\n",
    "    observed2 = np.zeros([loop,lat_obs_len,lon_obs_len])\n",
    "\n",
    "# Do the loop though the time steps and store data in a new observed variable.\n",
    "with tqdm(total=loop) as pbar:\n",
    "        for i in range(0,loop):\n",
    "            if dataset == '1' and contourf_var == '1':\n",
    "                var = nc_obs.variables['thetao'][i,0,latui:latli,lonli:lonui]\n",
    "                var = var.astype(np.float)\n",
    "                observed[i,:,:] = var \n",
    "            elif dataset == '1' and contourf_var=='2':\n",
    "                var1 = nc_obs.variables['uo'][i,0,latui:latli,lonli:lonui]\n",
    "                var2 = nc_obs.variables['vo'][i,0,latui:latli,lonli:lonui]\n",
    "                var1 = var1.astype(np.float)\n",
    "                var2 = var2.astype(np.float)\n",
    "                observed1[i,:,:] = var1\n",
    "                observed2[i,:,:] = var2     \n",
    "            elif dataset == '2':\n",
    "                var1 = nc_obs.variables['u'][i,0,latli:latui,lonli:lonui]\n",
    "                var2 = nc_obs.variables['v'][i,0,latli:latui,lonli:lonui]\n",
    "                var1 = var1.astype(np.float)\n",
    "                var2 = var2.astype(np.float)\n",
    "                observed1[i,:,:] = var1\n",
    "                observed2[i,:,:] = var2 \n",
    "            sleep(0.1)\n",
    "            pbar.update(1)\n",
    "if dataset == '1' and contourf_var== '2':\n",
    "    observed = np.sqrt(observed1**2 + observed2**2) \n",
    "if dataset == '2':\n",
    "    observed = np.sqrt(observed1**2 + observed2**2)\n",
    "if create_csv == '1':\n",
    "    # Reshaping matrix.\n",
    "    observed_reshape = observed.reshape(observed.shape[0], -1)\n",
    "    if dataset== '1' and contourf_var == '1':\n",
    "        # Saving reshaped array to file.\n",
    "        np.savetxt(\"observed_glorys_temp.csv\", observed_reshape)\n",
    "        # Retrieving data from file.\n",
    "        observed_reshape = np.loadtxt(\"observed_glorys_temp.csv\")\n",
    "    if dataset== '1' and contourf_var == '2':\n",
    "        # Saving reshaped array to file.\n",
    "        np.savetxt(\"observed_glorys_cur.csv\", observed_reshape)\n",
    "        # Retrieving data from file.\n",
    "        observed_reshape = np.loadtxt(\"observed_glorys_cur.csv\")\n",
    "    if dataset== '2':\n",
    "        # Saving reshaped array to file.\n",
    "        np.savetxt(\"observed_oscar.csv\", observed_reshape)\n",
    "        # Retrieving data from file.\n",
    "        observed_reshape = np.loadtxt(\"observed_oscar.csv\")\n",
    "    # The reshaped data is a 2D array, therefore we need to convert it to the original array shape.\n",
    "    # reshaping to get original matrice with original shape.\n",
    "    observed_reshape = observed_reshape.reshape(observed_reshape.shape[0], observed_reshape.shape[1] // observed.shape[2], observed.shape[2])\n",
    "else:\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Collect data from the resampled simulated data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open files and load lat/lon coords.\n",
    "nc_sim  = netCDF4.Dataset(roms_dir)\n",
    "lon_rho = nc_sim.variables['lon_rho'][:,:]\n",
    "lat_rho = nc_sim.variables['lat_rho'][:,:]\n",
    "\n",
    "# Calculate lat/lon coords based on the bounds chosen in step 2.\n",
    "i0,i1,j0,j1  = bbox2ij(lon_rho,lat_rho,bbox)\n",
    "lon_sim     = lon_rho[j0:j1, i0:i1]\n",
    "lat_sim     = lat_rho[j0:j1, i0:i1]\n",
    " \n",
    "# Lon/lat length.\n",
    "lat_sim_len = len(lat_rho[j0:j1,0])\n",
    "lon_sim_len = len(lon_rho[0, i0:i1])\n",
    "  \n",
    "# Create variable to store data.\n",
    "# Since MUR has a higher spatial resolution than ROMS output, change the expected variable.\n",
    "if dataset == '1' and contourf_var == '1':\n",
    "    var = np.zeros([loop,lat_sim_len,lon_sim_len])\n",
    "    expected = np.zeros([loop,lat_obs_len,lon_obs_len])\n",
    "if dataset == '1' and contourf_var == '2':\n",
    "    var1 = np.zeros([loop,lat_sim_len,lon_sim_len])\n",
    "    var2 = np.zeros([loop,lat_sim_len,lon_sim_len])\n",
    "    expected1 = np.zeros([loop,lat_obs_len,lon_obs_len])    \n",
    "    expected2 = np.zeros([loop,lat_obs_len,lon_obs_len])    \n",
    "if dataset == '2':\n",
    "    var1 = np.zeros([loop,lat_sim_len,lon_sim_len])\n",
    "    var2 = np.zeros([loop,lat_sim_len,lon_sim_len])\n",
    "    expected1 = np.zeros([loop,lat_obs_len,lon_obs_len])    \n",
    "    expected2 = np.zeros([loop,lat_obs_len,lon_obs_len])  \n",
    "\n",
    "# First step to resample simulate data.\n",
    "orig = pyresample.geometry.SwathDefinition(lons=lon_sim, lats=lat_sim)\n",
    "targ = pyresample.geometry.SwathDefinition(lons=lon_obs, lats=lat_obs)\n",
    "\n",
    "# Do the loop though the time steps and store data in a new observed variable.\n",
    "with tqdm(total=loop) as pbar:\n",
    "    for i in range(0,loop):\n",
    "        if dataset == '1' and contourf_var == '1':\n",
    "            var[:,:,:]         = nc_sim.variables['temp'][i,0,j0:j1, i0:i1]\n",
    "        elif dataset == '1' and contourf_var == '2':\n",
    "            var1[:,:,:]   = nc_sim.variables['u'][i,0,j0:j1, i0:i1]\n",
    "            var2[:,:,:]   = nc_sim.variables['v'][i,0,j0:j1, i0:i1] \n",
    "        elif dataset == '2':\n",
    "            var1[:,:,:] = nc_sim.variables['u'][i,0,j0:j1, i0:i1]\n",
    "            var2[:,:,:] = nc_sim.variables['v'][i,0,j0:j1, i0:i1]                  \n",
    "        sleep(0.1)\n",
    "        pbar.update(1)\n",
    "\n",
    "# Second loop to resample with the stored variable.\n",
    "with tqdm(total=loop) as pbar:\n",
    "    for i in range(0,loop,1):\n",
    "        if dataset == '1' and contourf_var=='1':          \n",
    "            expected[i,:,:] = pyresample.kd_tree.resample_gauss(orig, var[i,:,:], targ,radius_of_influence=50000, sigmas=25000, fill_value=None)\n",
    "        if dataset == '1' and contourf_var=='2':           \n",
    "            expected1[i,:,:] = pyresample.kd_tree.resample_gauss(orig, var1[i,:,:], targ,radius_of_influence=50000, sigmas=25000, fill_value=None)            \n",
    "            expected2[i,:,:] = pyresample.kd_tree.resample_gauss(orig, var2[i,:,:], targ,radius_of_influence=50000, sigmas=25000, fill_value=None)    \n",
    "        if dataset == '2':              \n",
    "            expected1[i,:,:] = pyresample.kd_tree.resample_gauss(orig, var1[i,:,:], targ,radius_of_influence=50000, sigmas=25000, fill_value=None)            \n",
    "            expected2[i,:,:] = pyresample.kd_tree.resample_gauss(orig, var2[i,:,:], targ,radius_of_influence=50000, sigmas=25000, fill_value=None)               \n",
    "        sleep(0.1)\n",
    "        pbar.update(1)\n",
    "\n",
    "if dataset == '1' and contourf_var=='2':                  \n",
    "    expected = np.sqrt(expected1**2 + expected2**2) \n",
    "elif dataset == '2':\n",
    "    expected = np.sqrt(expected1**2 + expected2**2) \n",
    "\n",
    "if create_csv == '1':\n",
    "    # Reshaping matrix.\n",
    "    expected_reshape = expected.reshape(expected.shape[0], -1)\n",
    "    if dataset== '1' and contourf_var == '1':\n",
    "        np.savetxt(\"expected_glorys_temp.csv\", expected_reshape)\n",
    "        # Retrieving data from file.\n",
    "        expected_reshape = np.loadtxt(\"expected_glorys_temp.csv\")\n",
    "    if dataset== '1' and contourf_var == '2':\n",
    "        np.savetxt(\"expected_glorys_cur.csv\", expected_reshape)\n",
    "        expected_reshape = np.loadtxt(\"expected_glorys_cur.csv\")\n",
    "    if dataset== '2':\n",
    "        np.savetxt(\"expected_oscar.csv\", expected_reshape)\n",
    "        expected_reshape = np.loadtxt(\"expected_oscar.csv\")\n",
    "    # The reshaped data is a 2D array, therefore we need to convert it to the original array shape.\n",
    "    # reshaping to get original matrice with original shape.\n",
    "    expected_reshape = expected_reshape.reshape(expected_reshape.shape[0], expected_reshape.shape[1] // expected.shape[2], expected.shape[2])\n",
    "else:\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Calculate the metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Root Mean Square Error.\n",
    "if metric == '1':\n",
    "    differences         = expected-observed\n",
    "    differences_squared = differences ** 2 \n",
    "    mean_of_differences_squared = np.average(differences_squared,axis=0)\n",
    "    val                 = np.sqrt(mean_of_differences_squared)\n",
    "\n",
    "# Calculate Mean Absolute Error.\n",
    "elif metric == '2':\n",
    "    val = np.abs((observed-expected)/observed).mean(axis=0)*100\n",
    "\n",
    "# Calculate Bias.\n",
    "elif metric == '3':\n",
    "    expected1 = np.average(expected,axis=0) \n",
    "    observed1 = np.average(observed,axis=0)\n",
    "    val       = expected1-observed1\n",
    "\n",
    "# If ROMS is coupled with WRF, the mask near the coawst may create dummy value. Nan then.\n",
    "val[val > 30000] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrange levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clevs_rmse = np.arange(0,5.05,0.01)\n",
    "ticks_rmse = np.arange(min(clevs_rmse),max(clevs_rmse),1)\n",
    "clevs_mape = np.arange(0,18.02,0.01)\n",
    "ticks_mape = np.arange(min(clevs_mape),max(clevs_mape),2)\n",
    "clevs_bias = np.arange(-1,1.1,0.01)\n",
    "ticks_bias = np.arange(min(clevs_bias),max(clevs_bias),0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  6. Create and plot map and then save. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create and plot map.\n",
    "m    = Basemap(projection='merc',llcrnrlat=bbox[2],urcrnrlat=bbox[3],llcrnrlon=bbox[0],urcrnrlon=bbox[1], lat_ts=30,resolution='i')\n",
    "fig  = plt.figure(1,figsize=(10,8))\n",
    "plt.xlabel('Longitude'u' [\\N{DEGREE SIGN}]',labelpad=18,size=10)\n",
    "plt.ylabel('Latitude'u' [\\N{DEGREE SIGN}]',labelpad=33,size=10)\n",
    "ax   = fig.add_subplot(111)\n",
    "m.drawparallels(np.arange(-90.,120.,1.), linewidth=0.00, color='black', labels=[1,0,0,1],labelstyle=\"N/S\",fontsize=10)\n",
    "m.drawmeridians(np.arange(-180.,180.,1.), linewidth=0.00,color='black', labels=[1,0,0,1],labelstyle=\"N/S\",fontsize=10)\n",
    "m.drawcountries(color = '#ffffff',linewidth=0.5)\n",
    "m.drawcoastlines(color = '#ffffff',linewidth=0.5)\n",
    "m.fillcontinents(color = '#000000')\n",
    "\n",
    "# Map ticks and gradient.\n",
    "if metric == '1':\n",
    "    clevs = clevs_rmse\n",
    "    ticks = ticks_rmse\n",
    "    cmap  = cmocean.cm.thermal\n",
    "elif metric == '2':\n",
    "    clevs = clevs_mape\n",
    "    ticks = ticks_mape\n",
    "    cmap  = cmocean.cm.thermal\n",
    "elif metric == '3':\n",
    "    clevs = clevs_bias\n",
    "    ticks = ticks_bias\n",
    "    cmap  = cmocean.cm.balance\n",
    "\n",
    "# Map pallete and plot\n",
    "if metric == '1' or metric == '2':\n",
    "    h1    = m.contourf(lon_obs, lat_obs, val, clevs,latlon=True,cmap=cmap,extend=\"both\") \n",
    "elif metric == '3':\n",
    "    h1    = m.contourf(lon_obs, lat_obs, val, clevs,latlon=True,cmap=cmap,norm=MidpointNormalize(midpoint=0),extend=\"both\")   \n",
    "cax   = fig.add_axes([0.37, 0.025, 0.27, 0.025])     \n",
    "cb    = fig.colorbar(h1, cax=cax, orientation=\"horizontal\",panchor=(0.5,0.5),shrink=0.3,ticks=ticks)\n",
    "\n",
    "# Map legend.\n",
    "if contourf_var == '1' and metric =='1':\n",
    "    cb.set_label(r'Sea Surface Temperature Root Mean Square Error [$^\\circ\\!$C]', fontsize=10, color='0.2',labelpad=-0.5)\n",
    "elif contourf_var == '1' and metric =='2':\n",
    "    cb.set_label(r'Sea Surface Temperature Mean Absolute Percentage Error [%]', fontsize=10, color='0.2',labelpad=-0.5)\n",
    "elif contourf_var == '1' and metric =='3':\n",
    "    cb.set_label(r'Sea Surface Temperature Bias [$^\\circ\\!$C]', fontsize=10, color='0.2',labelpad=-0.5)\n",
    "elif contourf_var == '2' and metric =='1':\n",
    "    cb.set_label(r'Current at Surface Root Mean Square Error [m.s⁻¹]', fontsize=10, color='0.2',labelpad=-0.5)\n",
    "elif contourf_var == '2' and metric =='2':\n",
    "    cb.set_label(r'Current at Surface Mean Absolute Percentage Error [m.s⁻¹]', fontsize=10, color='0.2',labelpad=-0.5)\n",
    "elif contourf_var == '2' and metric =='3':\n",
    "    cb.set_label(r'Current at Surface Bias [m.s⁻¹]', fontsize=10, color='0.2',labelpad=-0.5)\n",
    "cb.ax.tick_params(labelsize=10, length=2, color='0.2', labelcolor='0.2',direction='in') \n",
    "cb.set_ticks(ticks)\n",
    "\n",
    "# Create folder to store figures\n",
    "try:\n",
    "    os.makedirs(\"roms_evaluation\")\n",
    "except FileExistsError:\n",
    "    pass \n",
    "\n",
    "# Save figures.\n",
    "if dataset =='1' and metric =='1' and contourf_var == '1':\n",
    "    plt.savefig('./roms_evaluation/sst_rmse_roms_glorys.png', transparent=False, bbox_inches = 'tight', pad_inches=0, dpi=250)   \n",
    "elif dataset =='1' and metric =='2' and contourf_var == '1':\n",
    "    plt.savefig('./roms_evaluation/sst_mape_roms_glorys.png', transparent=False, bbox_inches = 'tight', pad_inches=0, dpi=250)   \n",
    "elif dataset =='1' and metric =='3' and contourf_var == '1':\n",
    "    plt.savefig('./roms_evaluation/sst_bias_roms_glorys.png', transparent=False, bbox_inches = 'tight', pad_inches=0, dpi=250)   \n",
    "elif dataset =='1' and metric =='1' and contourf_var == '2':\n",
    "    plt.savefig('./roms_evaluation/sc_rmse_roms_glorys.png', transparent=False, bbox_inches = 'tight', pad_inches=0, dpi=250)   \n",
    "elif dataset =='1' and metric =='2' and contourf_var == '2':\n",
    "    plt.savefig('./roms_evaluation/sc_mape_roms_glorys.png', transparent=False, bbox_inches = 'tight', pad_inches=0, dpi=250)   \n",
    "elif dataset =='1' and metric =='3' and contourf_var == '2':\n",
    "    plt.savefig('./roms_evaluation/sc_bias_roms_glorys.png', transparent=False, bbox_inches = 'tight', pad_inches=0, dpi=250)   \n",
    "elif dataset =='2' and metric=='1' and contourf_var == '1':\n",
    "    plt.savefig('./roms_evaluation/sst_rmse_roms_oscar.png', transparent=False, bbox_inches = 'tight', pad_inches=0, dpi=250)   \n",
    "elif dataset =='2' and metric =='2' and contourf_var == '1':\n",
    "    plt.savefig('./roms_evaluation/sst_mape_roms_oscar.png', transparent=False, bbox_inches = 'tight', pad_inches=0, dpi=250)   \n",
    "elif dataset =='2' and metric =='3' and contourf_var == '1':\n",
    "    plt.savefig('./roms_evaluation/sst_bias_roms_oscar.png', transparent=False, bbox_inches = 'tight', pad_inches=0, dpi=250)   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
